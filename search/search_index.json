{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AmrPlusPlus is an Easy to Use App that Identifies and Characterizes Resistance Genes within Sequence Data AmrPlusPlus is a Galaxy-based metagenomics pipeline that is intuitive and easy to use. The pipeline takes advantage of current and new tools to help identify and characterize resistance genes within metagenomic sequence data. The pipeline can be used under a local instance of Galaxy 1,2,3 and installed via Galaxy's Main Tool Shed. It is also available as a Galaxy-based Docker Image, using base images developed by Bj\u00f6rn Gr\u00fcning at the University of Freiburg. We recommend checking out his Github repository . for other Galaxy tools and workflows. What's Included in the Installation? AmrPlusPlus consist of: Trimmomatic 4 (for removal of low quality bases and sequences), BWA 5 (for detection of host DNA and resistance genes), Samtools 6 (for removal of host DNA), SNPFinder (for detection of haplotypes), ResistomeAnalyzer (for resistome analysis). RarefactionAnalyzer (for rarefaction analysis) Together, these tools make up the entire AmrPlusPlus pipeline. Only three inputs are required to run the pipeline: a single or paired fastq dataset, a resistance database (fasta), and a host genome (fasta). What is the goal of AmrPlusPlus? The goal of many metagenomics studies is to characterize the content and relative abundance of sequences of interest from the DNA of a given sample or set of samples. You may want to know what is contained within your sample or how abundant a given sequence is relative to another. Often, metagenomics is performed when the answer to these questions must be obtained for a large number of targets where techniques like multiplex PCR and other targeted methods would be too cumbersome to perform. AmrPlusPlus can process the raw data from the sequencer, identify the fragments of DNA, and count them. It also provides a count of the polymorphisms that occur in each DNA fragment with respect to the reference database. Additionally, you may want to know if the depth of your sequencing (how many reads you obtain that are on target) is high enough to identify rare organisms (organisms with low abundance relative to others) in your population. This is referred to as rarefaction and is calculated by randomly subsampling your sequence data at intervals between 0% and 100% in order to determine how many targets are found at each depth. AmrPlusPlus can perform this analysis as well. As a result of AmrPlusPlus, you will obtain count files for each sample that can be combined into a count matrix and analyzed using any statistical and mathematical techniques that can operate on a matrix of observations. For an example of a study where we have performed this using metagenomic sequencing data, you can read the open access manuscript entitled \u201cResistome diversity in cattle and the environment decreases during beef production\u201d.","title":"Introduction"},{"location":"#amrplusplus-is-an-easy-to-use-app-that-identifies-and-characterizes-resistance-genes-within-sequence-data","text":"AmrPlusPlus is a Galaxy-based metagenomics pipeline that is intuitive and easy to use. The pipeline takes advantage of current and new tools to help identify and characterize resistance genes within metagenomic sequence data. The pipeline can be used under a local instance of Galaxy 1,2,3 and installed via Galaxy's Main Tool Shed. It is also available as a Galaxy-based Docker Image, using base images developed by Bj\u00f6rn Gr\u00fcning at the University of Freiburg. We recommend checking out his Github repository . for other Galaxy tools and workflows.","title":"AmrPlusPlus is an Easy to Use App that Identifies and Characterizes Resistance Genes within Sequence Data"},{"location":"#whats-included-in-the-installation","text":"AmrPlusPlus consist of: Trimmomatic 4 (for removal of low quality bases and sequences), BWA 5 (for detection of host DNA and resistance genes), Samtools 6 (for removal of host DNA), SNPFinder (for detection of haplotypes), ResistomeAnalyzer (for resistome analysis). RarefactionAnalyzer (for rarefaction analysis) Together, these tools make up the entire AmrPlusPlus pipeline. Only three inputs are required to run the pipeline: a single or paired fastq dataset, a resistance database (fasta), and a host genome (fasta).","title":"What's Included in the Installation?"},{"location":"#what-is-the-goal-of-amrplusplus","text":"The goal of many metagenomics studies is to characterize the content and relative abundance of sequences of interest from the DNA of a given sample or set of samples. You may want to know what is contained within your sample or how abundant a given sequence is relative to another. Often, metagenomics is performed when the answer to these questions must be obtained for a large number of targets where techniques like multiplex PCR and other targeted methods would be too cumbersome to perform. AmrPlusPlus can process the raw data from the sequencer, identify the fragments of DNA, and count them. It also provides a count of the polymorphisms that occur in each DNA fragment with respect to the reference database. Additionally, you may want to know if the depth of your sequencing (how many reads you obtain that are on target) is high enough to identify rare organisms (organisms with low abundance relative to others) in your population. This is referred to as rarefaction and is calculated by randomly subsampling your sequence data at intervals between 0% and 100% in order to determine how many targets are found at each depth. AmrPlusPlus can perform this analysis as well. As a result of AmrPlusPlus, you will obtain count files for each sample that can be combined into a count matrix and analyzed using any statistical and mathematical techniques that can operate on a matrix of observations. For an example of a study where we have performed this using metagenomic sequencing data, you can read the open access manuscript entitled \u201cResistome diversity in cattle and the environment decreases during beef production\u201d.","title":"What is the goal of AmrPlusPlus?"},{"location":"analysisoutput/","text":"What Does AmrPlusPlus Produce? This section explains the files that you will receive after AmrPlusPlus is finished running. There are a total of 9 files: 4 resistome files, 4 rarefaction files, and 1 SNP file. The output used in the following sections is real output generated using the example data provided on the AmrPlusPlus website. 1. Resistome Analysis The resistome (counts of resistance genes found in your data) are generated in the following order: Note gene-level counts \u2192 Group-level counts \u2192 Mechanism-level counts \u2192 Class-level counts Four files are produced from this analysis step; each file corresponds to an annotation level in the MEGARes database: Class, Mechanism, Group, and gene (sequence-level). Because alignments were performed at the gene level, this file is the starting point for analysis. Within the file gene_level_resistome.tsv, each row represents a data entry, and there are four tab-separated columns. An example is provided below, and each field is individually explained: gene_level_resistome.tsv Sample Gene Hits Gene Fraction dataset_14 gi|13562034|gb|AF351241.1|betalactams|Class_A_betalactamases|TEM 5 32.3158 dataset_14 gi|14588992|emb|AJ277415.1|betalactams|Class_A_betalactamases|TEM 2 14.6341 dataset_14 gi|145975406|gb|EF534736.1|betalactams|Class_A_betalactamases|TEM 2 23.4637 dataset_14 gi|1488048|gb|U63835.1|PAU63835|betalactams|Class_D_betalactamases|OXA 1 10.678 dataset_14 gi|149167|gb|M88143.1|KPNBETALAC|betalactams|Class_A_betalactamases|TEM 1 9.93691 Sample: this is the sample ID to which the data belong and is typically related to the name of the input file. Gene: this field is the target gene from the MEGARes database (or whichever database you chose to use during alignment). These are the genes from the database that were found in your input data. If you're using MEGARes as a database, you can copy and paste the gene name into the MEGARes website search bar and it will provide additional information about that particular gene. Hits: this field is the number of short reads that aligned to that particular gene. We use this as a \u201ccount\u201d of how many times a given gene is \u201cseen\u201d in the data. These counts can be analyzed relative to counts of other genes. Gene Fraction: we define gene fraction as the percentage of the gene that is covered by at least one read. For example, if a gene has a fraction of 100%, then every nucleotide in that gene has at least one (or more) reads aligning to it. We use this field as a filter to reduce the number of false positives found in our output data. For instance, in the MEG lab, we do not count genes that have a fraction below 80%, so only genes that are covered more than 80% are used to generate counts for statistical analysis. The counts in this gene-level file are then aggregated up through the annotation graph to produce counts at the Group, then Mechanism, then Class level. In the example above, our next level up from gene is Group, and the Group file would look like so: group_level_resistome.tsv Sample Group Hits dataset_14 OXA 1 dataset_14 TEM 10 Note Fields are the same, except there is no Gene Fraction field in this file. Because alignment is performed on the genes, and the Gene Fraction information is calculated using alignment data, the gene-level file is the only one that contains Gene Fraction information. All genes that pass the Gene Fraction threshold will be counted into the next file at the Group level. Here, because we had two Groups represented in our lowest-level file, we see counts for two groups that are equal to the sum of the gene counts in the previous file. The next level up from Group is the Mechanism level, and the Mechanism file would look like so: mechanism_level_resistome.tsv Sample Mechanism Hits dataset_14 Class_D_betalactamases 1 dataset_14 Class_A_betalactamases 10 Because the TEM betalactamases are Ambler Class A betalactamases, their mechanism is \u201cClass_A_betalactamases\u201d. There are 10 counts for the Class A betalactamases because there were 10 counts for TEM in the Group file. Likewise, the OXA betalactamases are Ambler Class D, and therefore we see 1 count for Class D betalactamases in the Mechanism-level file. The next level up from Mechanism is the Class level, and the Class level file would look like so: class_level_resistome.tsv Sample Class Hits dataset_14 betalactams 11 The Class level is the highest level and includes the major drug classes of antimicrobial resistance. In this case, all of our counts were betalactamases, so we see that all 11 counts are now represented in the betalactams Class field. These four files comprise the output for the resistome analysis and can be combined across multiple samples to produce a count matrix for analysis. A count matrix is a matrix of counts where the rows are the term of interest (e.g. betalactams), the columns are the sample names, and the matrix is filled in with the counts for each of term of interest within each sample. Alternatively, the rows could be sample names and the columns the term of interest. For suggestions on how to analyze and interpret count data, see the \u201cHow do I interpret the AmrPlusPlus output\u201d section. 2. Rarefaction Analysis Rarefaction is an ecological measure of how much of the biological diversity we have captured at a given sampling level. The generation of a rarefaction curve involves, for each sample, picking random sequences from that data and generating counts of how many unique genes were observed. Alternatively, we could ask how many unique Groups, Mechanisms, or Classes were observed at a given sampling level. RarefactionAnalyzer will take three random draws at increments of 5% sampling level, so 5% of the raw data, 10%, \u2026 , 100%. The number of unique genes, Groups, Mechanisms, and Classes are then plotted as a function of sampling depth. An example is provided here for our example data at the gene level. Ideally, we would see curves that flatten out toward the right-hand side of the graph (at the 100% sampling level), as this means that we have captured much of the diversity in our sample population. So for this particular figure, we have capture a lot of the diversity but could probably sample deeper in future studies. We largely obtain this result because our sample dataset is small for convenience of showcasing our pipeline. Real data will look slightly different. Rarefaction Gen Plot Graph How do I interpret the AmrPlusPlus output? At the conclusion of running AmrPlusPlus, you have four graphs, four files with counts, and a single file with SNP data from that sample. The graphs should be interpreted as described above for rarefaction analysis. View Gene Graph View Group Graph View Mechanism Graph View Class Graph The count data should be combined with other samples in your experiment into a count matrix. A count matrix is a matrix of counts where the rows are the term of interest (e.g. betalactams), the columns are the sample names, and the matrix is filled in with the counts for each of term of interest within each sample. Alternatively, the rows could be sample names and the columns the term of interest. You can then use this count matrix as input for many statistical or descriptive procedures, including but not limitd to the following: Principal components analysis Non-metric multidimensional scaling Zero-inflated Gaussian Mixture Models (for example, with the metagenomeseq R package) Linear discriminant analysis The primary question that you'll want to ask of your data depends on your experimental design. However, this question usually involves some kind of comparison between groups: does group A have more betalactamases than group B? How does the resistome differ between group A and group B? Is that significant? What major features in group A make it significantly differ from group B? These kinds of questions are mostly statistical, and any tool that accepts count data can be used for further analysis. Because this is nearly identical to microbiome analysis, there are plenty of tools out there that can aid in further statistical exploration, such as the R package metagenomeseq .","title":"Example Analysis and Output"},{"location":"analysisoutput/#what-does-amrplusplus-produce","text":"This section explains the files that you will receive after AmrPlusPlus is finished running. There are a total of 9 files: 4 resistome files, 4 rarefaction files, and 1 SNP file. The output used in the following sections is real output generated using the example data provided on the AmrPlusPlus website.","title":"What Does AmrPlusPlus Produce?"},{"location":"analysisoutput/#1-resistome-analysis","text":"The resistome (counts of resistance genes found in your data) are generated in the following order: Note gene-level counts \u2192 Group-level counts \u2192 Mechanism-level counts \u2192 Class-level counts Four files are produced from this analysis step; each file corresponds to an annotation level in the MEGARes database: Class, Mechanism, Group, and gene (sequence-level). Because alignments were performed at the gene level, this file is the starting point for analysis. Within the file gene_level_resistome.tsv, each row represents a data entry, and there are four tab-separated columns. An example is provided below, and each field is individually explained: gene_level_resistome.tsv Sample Gene Hits Gene Fraction dataset_14 gi|13562034|gb|AF351241.1|betalactams|Class_A_betalactamases|TEM 5 32.3158 dataset_14 gi|14588992|emb|AJ277415.1|betalactams|Class_A_betalactamases|TEM 2 14.6341 dataset_14 gi|145975406|gb|EF534736.1|betalactams|Class_A_betalactamases|TEM 2 23.4637 dataset_14 gi|1488048|gb|U63835.1|PAU63835|betalactams|Class_D_betalactamases|OXA 1 10.678 dataset_14 gi|149167|gb|M88143.1|KPNBETALAC|betalactams|Class_A_betalactamases|TEM 1 9.93691 Sample: this is the sample ID to which the data belong and is typically related to the name of the input file. Gene: this field is the target gene from the MEGARes database (or whichever database you chose to use during alignment). These are the genes from the database that were found in your input data. If you're using MEGARes as a database, you can copy and paste the gene name into the MEGARes website search bar and it will provide additional information about that particular gene. Hits: this field is the number of short reads that aligned to that particular gene. We use this as a \u201ccount\u201d of how many times a given gene is \u201cseen\u201d in the data. These counts can be analyzed relative to counts of other genes. Gene Fraction: we define gene fraction as the percentage of the gene that is covered by at least one read. For example, if a gene has a fraction of 100%, then every nucleotide in that gene has at least one (or more) reads aligning to it. We use this field as a filter to reduce the number of false positives found in our output data. For instance, in the MEG lab, we do not count genes that have a fraction below 80%, so only genes that are covered more than 80% are used to generate counts for statistical analysis. The counts in this gene-level file are then aggregated up through the annotation graph to produce counts at the Group, then Mechanism, then Class level. In the example above, our next level up from gene is Group, and the Group file would look like so: group_level_resistome.tsv Sample Group Hits dataset_14 OXA 1 dataset_14 TEM 10 Note Fields are the same, except there is no Gene Fraction field in this file. Because alignment is performed on the genes, and the Gene Fraction information is calculated using alignment data, the gene-level file is the only one that contains Gene Fraction information. All genes that pass the Gene Fraction threshold will be counted into the next file at the Group level. Here, because we had two Groups represented in our lowest-level file, we see counts for two groups that are equal to the sum of the gene counts in the previous file. The next level up from Group is the Mechanism level, and the Mechanism file would look like so: mechanism_level_resistome.tsv Sample Mechanism Hits dataset_14 Class_D_betalactamases 1 dataset_14 Class_A_betalactamases 10 Because the TEM betalactamases are Ambler Class A betalactamases, their mechanism is \u201cClass_A_betalactamases\u201d. There are 10 counts for the Class A betalactamases because there were 10 counts for TEM in the Group file. Likewise, the OXA betalactamases are Ambler Class D, and therefore we see 1 count for Class D betalactamases in the Mechanism-level file. The next level up from Mechanism is the Class level, and the Class level file would look like so: class_level_resistome.tsv Sample Class Hits dataset_14 betalactams 11 The Class level is the highest level and includes the major drug classes of antimicrobial resistance. In this case, all of our counts were betalactamases, so we see that all 11 counts are now represented in the betalactams Class field. These four files comprise the output for the resistome analysis and can be combined across multiple samples to produce a count matrix for analysis. A count matrix is a matrix of counts where the rows are the term of interest (e.g. betalactams), the columns are the sample names, and the matrix is filled in with the counts for each of term of interest within each sample. Alternatively, the rows could be sample names and the columns the term of interest. For suggestions on how to analyze and interpret count data, see the \u201cHow do I interpret the AmrPlusPlus output\u201d section.","title":"1. Resistome Analysis"},{"location":"analysisoutput/#2-rarefaction-analysis","text":"Rarefaction is an ecological measure of how much of the biological diversity we have captured at a given sampling level. The generation of a rarefaction curve involves, for each sample, picking random sequences from that data and generating counts of how many unique genes were observed. Alternatively, we could ask how many unique Groups, Mechanisms, or Classes were observed at a given sampling level. RarefactionAnalyzer will take three random draws at increments of 5% sampling level, so 5% of the raw data, 10%, \u2026 , 100%. The number of unique genes, Groups, Mechanisms, and Classes are then plotted as a function of sampling depth. An example is provided here for our example data at the gene level. Ideally, we would see curves that flatten out toward the right-hand side of the graph (at the 100% sampling level), as this means that we have captured much of the diversity in our sample population. So for this particular figure, we have capture a lot of the diversity but could probably sample deeper in future studies. We largely obtain this result because our sample dataset is small for convenience of showcasing our pipeline. Real data will look slightly different. Rarefaction Gen Plot Graph","title":"2. Rarefaction Analysis"},{"location":"analysisoutput/#how-do-i-interpret-the-amrplusplus-output","text":"At the conclusion of running AmrPlusPlus, you have four graphs, four files with counts, and a single file with SNP data from that sample. The graphs should be interpreted as described above for rarefaction analysis. View Gene Graph View Group Graph View Mechanism Graph View Class Graph The count data should be combined with other samples in your experiment into a count matrix. A count matrix is a matrix of counts where the rows are the term of interest (e.g. betalactams), the columns are the sample names, and the matrix is filled in with the counts for each of term of interest within each sample. Alternatively, the rows could be sample names and the columns the term of interest. You can then use this count matrix as input for many statistical or descriptive procedures, including but not limitd to the following: Principal components analysis Non-metric multidimensional scaling Zero-inflated Gaussian Mixture Models (for example, with the metagenomeseq R package) Linear discriminant analysis The primary question that you'll want to ask of your data depends on your experimental design. However, this question usually involves some kind of comparison between groups: does group A have more betalactamases than group B? How does the resistome differ between group A and group B? Is that significant? What major features in group A make it significantly differ from group B? These kinds of questions are mostly statistical, and any tool that accepts count data can be used for further analysis. Because this is nearly identical to microbiome analysis, there are plenty of tools out there that can aid in further statistical exploration, such as the R package metagenomeseq .","title":"How do I interpret the AmrPlusPlus output?"},{"location":"citing/","text":"Citing AMR++ Lakin,S.M., Dean,C., Noyes,N.R., Dettenwanger,A., Ross,A.S., Doster,E., Rovira,P., Abdo,Z., Jones,K.L., Ruiz,J., et al. (2017) MEGARes: an antimicrobial resistance database for high throughput sequencing. Nucleic Acids Res., 45, D574\u2013D580.","title":"Citing AMR++"},{"location":"citing/#citing-amr","text":"Lakin,S.M., Dean,C., Noyes,N.R., Dettenwanger,A., Ross,A.S., Doster,E., Rovira,P., Abdo,Z., Jones,K.L., Ruiz,J., et al. (2017) MEGARes: an antimicrobial resistance database for high throughput sequencing. Nucleic Acids Res., 45, D574\u2013D580.","title":"Citing AMR++"},{"location":"contact/","text":"Contact Questions, bugs, or feature requests should be directed to meglab.metagenomics@gmail.com","title":"Contact"},{"location":"contact/#contact","text":"Questions, bugs, or feature requests should be directed to meglab.metagenomics@gmail.com","title":"Contact"},{"location":"references/","text":"References Goecks, J, Nekrutenko, A, Taylor, J and The Galaxy Team. Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences. Genome Biol. 2010 Aug 25;11(8):R86. Blankenberg D, Von Kuster G, Coraor N, Ananda G, Lazarus R, Mangan M, Nekrutenko A, Taylor J. \"Galaxy: a web-based genome analysis tool for experimentalists\". Current Protocols in Molecular Biology. 2010 Jan; Chapter 19:Unit 19.10.1-21. Giardine B, Riemer C, Hardison RC, Burhans R, Elnitski L, Shah P, Zhang Y, Blankenberg D, Albert I, Taylor J, Miller W, Kent WJ, Nekrutenko A. \"Galaxy: a platform for interactive large-scale genome analysis.\" Genome Research. 2005 Oct; 15(10):1451-5. Bolger, A. M., Lohse, M., & Usadel, B. (2014). Trimmomatic: A flexible trimmer for Illumina Sequence Data. Bioinformatics, btu170. Li H. and Durbin R. (2009) Fast and accurate short read alignment with Burrows-Wheeler Transform. Bioinformatics, 25:1754-60. Li H, Handsaker B, Wysoker A, et al. The Sequence Alignment/Map format and SAMtools. Bioinformatics. 2009;25(16):2078-2079. doi:10.1093/bioinformatics/btp352.","title":"References"},{"location":"references/#references","text":"Goecks, J, Nekrutenko, A, Taylor, J and The Galaxy Team. Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences. Genome Biol. 2010 Aug 25;11(8):R86. Blankenberg D, Von Kuster G, Coraor N, Ananda G, Lazarus R, Mangan M, Nekrutenko A, Taylor J. \"Galaxy: a web-based genome analysis tool for experimentalists\". Current Protocols in Molecular Biology. 2010 Jan; Chapter 19:Unit 19.10.1-21. Giardine B, Riemer C, Hardison RC, Burhans R, Elnitski L, Shah P, Zhang Y, Blankenberg D, Albert I, Taylor J, Miller W, Kent WJ, Nekrutenko A. \"Galaxy: a platform for interactive large-scale genome analysis.\" Genome Research. 2005 Oct; 15(10):1451-5. Bolger, A. M., Lohse, M., & Usadel, B. (2014). Trimmomatic: A flexible trimmer for Illumina Sequence Data. Bioinformatics, btu170. Li H. and Durbin R. (2009) Fast and accurate short read alignment with Burrows-Wheeler Transform. Bioinformatics, 25:1754-60. Li H, Handsaker B, Wysoker A, et al. The Sequence Alignment/Map format and SAMtools. Bioinformatics. 2009;25(16):2078-2079. doi:10.1093/bioinformatics/btp352.","title":"References"},{"location":"documentation/docker/","text":"Docker Commands Reference Guide Overview Below, we will cover some of the basic Docker commands that you will find useful when interacting with Docker containers. Many of these commands can be found on the Docker commands homepage and from the Galaxy Docker Github repository. They are simply reviewed here for convenience. Container Commands Runs the chrisd/amrplusplus container in the background with no FTP server $ docker run -d -p 8080:80 chrisd/amrplusplus Runs the chrisd/amrplusplus container in the background with an FTP server $ docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus Provides information about currently running containers $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6296a2688b71 chrisd/amrplusplus \"/usr/bin/startup\" 10 hours ago Up 10 hours 8800/tcp, 9002/tcp, 0.0.0.0:8021->21/tcp, 0.0.0.0:8080->80/tcp elated_cray Stops the currently running container specified by the CONTAINER ID $ docker stop 6296a2688b71 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Provides information about currently saved images $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE chrisd/amrplusplus latest 976681113852 3 days ago 1.623 GB Interact with a running container You will be launched into a Bash shell and allowed to explore the container. $ docker run -i -t -p 8080:80 chrisd/amrplusplus /bin/bash root@d49e4fa1bd22:/galaxy-central# Give a running Galaxy container persistent storage By DEFAULT, Galaxy containers are volatile, meaning that once they are stopped, all data and uploaded files will be removed. This command can be used to give a running Galaxy container persistent storage $ docker run -d -p 8080:80 -v /home/user/galaxy_storage/:/export/ chrisd/amrplusplus","title":"Docker Commands"},{"location":"documentation/docker/#docker-commands-reference-guide","text":"","title":"Docker Commands Reference Guide"},{"location":"documentation/docker/#overview","text":"Below, we will cover some of the basic Docker commands that you will find useful when interacting with Docker containers. Many of these commands can be found on the Docker commands homepage and from the Galaxy Docker Github repository. They are simply reviewed here for convenience.","title":"Overview"},{"location":"documentation/docker/#container-commands","text":"Runs the chrisd/amrplusplus container in the background with no FTP server $ docker run -d -p 8080:80 chrisd/amrplusplus Runs the chrisd/amrplusplus container in the background with an FTP server $ docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus Provides information about currently running containers $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6296a2688b71 chrisd/amrplusplus \"/usr/bin/startup\" 10 hours ago Up 10 hours 8800/tcp, 9002/tcp, 0.0.0.0:8021->21/tcp, 0.0.0.0:8080->80/tcp elated_cray Stops the currently running container specified by the CONTAINER ID $ docker stop 6296a2688b71 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Provides information about currently saved images $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE chrisd/amrplusplus latest 976681113852 3 days ago 1.623 GB Interact with a running container You will be launched into a Bash shell and allowed to explore the container. $ docker run -i -t -p 8080:80 chrisd/amrplusplus /bin/bash root@d49e4fa1bd22:/galaxy-central# Give a running Galaxy container persistent storage By DEFAULT, Galaxy containers are volatile, meaning that once they are stopped, all data and uploaded files will be removed. This command can be used to give a running Galaxy container persistent storage $ docker run -d -p 8080:80 -v /home/user/galaxy_storage/:/export/ chrisd/amrplusplus","title":"Container Commands"},{"location":"documentation/pipeline/","text":"Pipeline Description Below we explain the use of each component in the AmrPlusPlus pipeline. Step 1: Input Input The raw data input to AmrPlusPlus will be a single pair of fastq files, one forward and one reverse. Additionally, you will need a database file in FASTA format (for the targets you wish to find in your data) such as the MEGARes database file, and a FASTA file for a host organism. Step 2: Quality Control Quality Control Depending on the sequencing platform, your data will likely contain some kind of error or bias. For Illumina sequencers, the quality of the sequence (the confidence that a given nucleotide is correct) drops off toward the end of the read. For Proton Torrent machines, there will be tandem repeats of nucleotides that aren't correct. Additionally, random error will be dispersed throughout. Quality control programs utilize statistics and other mathematical conventions to remove these regions of error from your data. While it is not necessarily required, it is highly recommended to run a quality control program on your raw data, as it is fairly efficient and will give you information about the quality of the sequencing performed on your samples. Ideally, less than 10% of the data will be of poor quality. For AmrPlusPlus, we use Trimmomatic 4 to perform quality control. Step 3: Removal of Host DNA Removal of Host DNA If your samples are collected from an animal source, there will be DNA that is off-target in your sample. We define off-target as being a sequence that is not contained within the database of interest, so for our typical use case, this would be any DNA that is not related to antimicrobial resistance. While it is not required to perform this step, it is recommended, as it can reduce the rate of false positive classifications. Reviewers have also commented on the quality of the pipeline when this step has been left out in our previous manuscripts, so we now perform host removal on all samples. We use the Burrows Wheeler Aligner 5 and a FASTA file of known host genetic sequences to match reads from the sample to the host genome. We then utilize Samtools 6 to filter out the reads that align to the host genome. Step 4: Alignment to Target Database Alignment to Target Database This step is the same as the prior step, except we use the database of interest for alignment. This will match the raw short read sequences to the target database using BWA and provide a SAM file as output. SAM stands for Sequence Alignment/Map and provides information for how the short fragments map to the database sequences; the SAM file specification is fairly detailed, so these files are large and often contain information that isn't useful in many contexts. We have written programs to parse this file and obtain the information of interest about the aligned reads. Step 5: Resistome Analysis Resistome Analysis This part of the pipeline takes the SAM file generated in Step 4 and transforms it into the sample resistome. It does this by counting each alignment for each gene found in the SAM file (1 aligned read = 1 count). The output consists of 4 tab-delimited text files, one for each level of the database hierarchy (gene, group, mechanism and class). Within each file, the first column lists the sample that was analyzed (taken from the file name), the second column lists the gene, group, mechanism or class that was identified, and the third column gives the total count of reads that aligned to that gene, group, mechanism or class. For the gene-level output, there is a fourth column that lists the gene fraction. Gene fraction is defined as the proportion of nucleotides in the reference sequence that were aligned to by at least one sequence read. Our program allows you to set a gene fraction threshold at which genes are considered to be positively identified in the sample. This threshold is meant to decrease false positive identification. For example, if you set the gene fraction threshold at 80%, then only genes with at least 80% nucleotide coverage will be included in the output. Step 6: Rarefaction Analysis Rarefaction Analysis If a rarefaction analysis is desired, our program called RarefactionAnalyzer can perform it at this step. Rarefaction can be of interest when you wish to know the fraction of the target population that is captured in your sequence data versus the fraction of the target population that has not been described due to not sequencing deep enough. This is a standard analysis performed for microbiome research and is typically recommended for any kind of metagenomics where counts are of interest. Using our program, you are able to specify the increments (i.e., \"levels\") of your rarefaction (i.e., whether you subsample your sequence data in 5-percent increments, 20-percent increments, etc...), and the number of random subsamples (i.e., \"iterations\") to perform at each increment. In order to obtain a smooth rarefaction curve, we suggest performing at least 5 iterations at each level so that each point on the curve is an average of at least 5 random subsamples. In addition to setting the \"level\" and \"iteration\" parameters, you are also able to apply a gene fraction threshold to the rarefaction analysis (see Step 5 for more details). The output of the Rarefaction Analysis includes 4 rarefaction curves -- one for each level of the annotation hierarchy (gene, group, mechanism and class). For each graph, the x-axis is the rarefaction level (from 0 to 100%), and the y-axis is the number of unique genes, group, mechanisms or classes identified in the rarefied data. Step 7: Read-pair Haplotyping Read-pair Haplotyping Variants are defined as nucleotides that differ from the reference database target. For reads that have aligned to a given reference sequence, we check each nucleotide against the reference target to determine if a variant is present. If multiple variants are present on the same read pair, we can make the assumption that they come from the same fragment of DNA (the same organism), so we record these variants that fall on the same read pair as haplotypes. The output from the variant calling step is a count file similar to the Resistome Analysis step, however the counts are of the haplotypes as determined with respect to the reference target. This information can be used in statistical analysis of counts, as in the previous step, or variants of interest can be manually found in the file if they are of interest. Output from this module is a tab delimited text file with three columns: Gene: Name of the gene that contains the corresponding haplotype Haplotype Pattern: Location(s) of each SNP, followed by reference nucleotide -> variant nucleotide. SNP locations and variants are separated by full colons. Occurrence: The number of reads (or read pairs) with the given haplotype pattern. Output Gene Haplotype Pattern Occurrence gene1 494T->A:987C->A:1001A->T 2 gene2 56T->A:80A->C:93A->C:109T->A 8 gene3 285T->A:1022:C->G 3 gene4 585T->A:1051:C->A 1 Output As output from running AmrPlusPlus, you will receive two files for each sample: a file with a count of how many reads aligned to each target from the reference database, and a file with a count of haplotypes that were detected within aligned reads. Our recommendation is to then combine files of the same type into two \u201cmaster\u201d files that are count matrices. Depending on the subsequent application you will be using for statistical analysis, you may want to arrange the matrices with gene targets as rows and the samples as columns, where the counts of the targets are the entries in the matrix. Alternatively, you could transpose that matrix and have the gene targets be the columns and the samples be the rows. Next Steps With the two count matrices, you can then perform statistical analyses using publicly available tools. We make use of the R programming language and the package metagenomeseq to perform a count matrix analysis. The questions that are typically asked of count data are: How similar or different are the samples, both by pairwise comparison and by study design? If there is a time series in the experimental design, is there a significant trend over time related to the count data? Are the statistically significant differences related to any biologically meaningful group of targets? The metagenomeseq package can perform the analyses in (1) and (2), and the user can obtain information about (3) based on the results. Another option, if relative abundance changes are of interest, is to use an RNA-seq count matrix analysis package such as DESeq2 (also an R package) to gather statistics on the log-fold changes from one sample group to another.","title":"Pipeline Description"},{"location":"documentation/pipeline/#pipeline-description","text":"Below we explain the use of each component in the AmrPlusPlus pipeline. Step 1: Input","title":"Pipeline Description"},{"location":"documentation/pipeline/#input","text":"The raw data input to AmrPlusPlus will be a single pair of fastq files, one forward and one reverse. Additionally, you will need a database file in FASTA format (for the targets you wish to find in your data) such as the MEGARes database file, and a FASTA file for a host organism. Step 2: Quality Control","title":"Input"},{"location":"documentation/pipeline/#quality-control","text":"Depending on the sequencing platform, your data will likely contain some kind of error or bias. For Illumina sequencers, the quality of the sequence (the confidence that a given nucleotide is correct) drops off toward the end of the read. For Proton Torrent machines, there will be tandem repeats of nucleotides that aren't correct. Additionally, random error will be dispersed throughout. Quality control programs utilize statistics and other mathematical conventions to remove these regions of error from your data. While it is not necessarily required, it is highly recommended to run a quality control program on your raw data, as it is fairly efficient and will give you information about the quality of the sequencing performed on your samples. Ideally, less than 10% of the data will be of poor quality. For AmrPlusPlus, we use Trimmomatic 4 to perform quality control. Step 3: Removal of Host DNA","title":"Quality Control"},{"location":"documentation/pipeline/#removal-of-host-dna","text":"If your samples are collected from an animal source, there will be DNA that is off-target in your sample. We define off-target as being a sequence that is not contained within the database of interest, so for our typical use case, this would be any DNA that is not related to antimicrobial resistance. While it is not required to perform this step, it is recommended, as it can reduce the rate of false positive classifications. Reviewers have also commented on the quality of the pipeline when this step has been left out in our previous manuscripts, so we now perform host removal on all samples. We use the Burrows Wheeler Aligner 5 and a FASTA file of known host genetic sequences to match reads from the sample to the host genome. We then utilize Samtools 6 to filter out the reads that align to the host genome. Step 4: Alignment to Target Database","title":"Removal of Host DNA"},{"location":"documentation/pipeline/#alignment-to-target-database","text":"This step is the same as the prior step, except we use the database of interest for alignment. This will match the raw short read sequences to the target database using BWA and provide a SAM file as output. SAM stands for Sequence Alignment/Map and provides information for how the short fragments map to the database sequences; the SAM file specification is fairly detailed, so these files are large and often contain information that isn't useful in many contexts. We have written programs to parse this file and obtain the information of interest about the aligned reads. Step 5: Resistome Analysis","title":"Alignment to Target Database"},{"location":"documentation/pipeline/#resistome-analysis","text":"This part of the pipeline takes the SAM file generated in Step 4 and transforms it into the sample resistome. It does this by counting each alignment for each gene found in the SAM file (1 aligned read = 1 count). The output consists of 4 tab-delimited text files, one for each level of the database hierarchy (gene, group, mechanism and class). Within each file, the first column lists the sample that was analyzed (taken from the file name), the second column lists the gene, group, mechanism or class that was identified, and the third column gives the total count of reads that aligned to that gene, group, mechanism or class. For the gene-level output, there is a fourth column that lists the gene fraction. Gene fraction is defined as the proportion of nucleotides in the reference sequence that were aligned to by at least one sequence read. Our program allows you to set a gene fraction threshold at which genes are considered to be positively identified in the sample. This threshold is meant to decrease false positive identification. For example, if you set the gene fraction threshold at 80%, then only genes with at least 80% nucleotide coverage will be included in the output. Step 6: Rarefaction Analysis","title":"Resistome Analysis"},{"location":"documentation/pipeline/#rarefaction-analysis","text":"If a rarefaction analysis is desired, our program called RarefactionAnalyzer can perform it at this step. Rarefaction can be of interest when you wish to know the fraction of the target population that is captured in your sequence data versus the fraction of the target population that has not been described due to not sequencing deep enough. This is a standard analysis performed for microbiome research and is typically recommended for any kind of metagenomics where counts are of interest. Using our program, you are able to specify the increments (i.e., \"levels\") of your rarefaction (i.e., whether you subsample your sequence data in 5-percent increments, 20-percent increments, etc...), and the number of random subsamples (i.e., \"iterations\") to perform at each increment. In order to obtain a smooth rarefaction curve, we suggest performing at least 5 iterations at each level so that each point on the curve is an average of at least 5 random subsamples. In addition to setting the \"level\" and \"iteration\" parameters, you are also able to apply a gene fraction threshold to the rarefaction analysis (see Step 5 for more details). The output of the Rarefaction Analysis includes 4 rarefaction curves -- one for each level of the annotation hierarchy (gene, group, mechanism and class). For each graph, the x-axis is the rarefaction level (from 0 to 100%), and the y-axis is the number of unique genes, group, mechanisms or classes identified in the rarefied data. Step 7: Read-pair Haplotyping","title":"Rarefaction Analysis"},{"location":"documentation/pipeline/#read-pair-haplotyping","text":"Variants are defined as nucleotides that differ from the reference database target. For reads that have aligned to a given reference sequence, we check each nucleotide against the reference target to determine if a variant is present. If multiple variants are present on the same read pair, we can make the assumption that they come from the same fragment of DNA (the same organism), so we record these variants that fall on the same read pair as haplotypes. The output from the variant calling step is a count file similar to the Resistome Analysis step, however the counts are of the haplotypes as determined with respect to the reference target. This information can be used in statistical analysis of counts, as in the previous step, or variants of interest can be manually found in the file if they are of interest. Output from this module is a tab delimited text file with three columns: Gene: Name of the gene that contains the corresponding haplotype Haplotype Pattern: Location(s) of each SNP, followed by reference nucleotide -> variant nucleotide. SNP locations and variants are separated by full colons. Occurrence: The number of reads (or read pairs) with the given haplotype pattern. Output Gene Haplotype Pattern Occurrence gene1 494T->A:987C->A:1001A->T 2 gene2 56T->A:80A->C:93A->C:109T->A 8 gene3 285T->A:1022:C->G 3 gene4 585T->A:1051:C->A 1 Output As output from running AmrPlusPlus, you will receive two files for each sample: a file with a count of how many reads aligned to each target from the reference database, and a file with a count of haplotypes that were detected within aligned reads. Our recommendation is to then combine files of the same type into two \u201cmaster\u201d files that are count matrices. Depending on the subsequent application you will be using for statistical analysis, you may want to arrange the matrices with gene targets as rows and the samples as columns, where the counts of the targets are the entries in the matrix. Alternatively, you could transpose that matrix and have the gene targets be the columns and the samples be the rows. Next Steps With the two count matrices, you can then perform statistical analyses using publicly available tools. We make use of the R programming language and the package metagenomeseq to perform a count matrix analysis. The questions that are typically asked of count data are: How similar or different are the samples, both by pairwise comparison and by study design? If there is a time series in the experimental design, is there a significant trend over time related to the count data? Are the statistically significant differences related to any biologically meaningful group of targets? The metagenomeseq package can perform the analyses in (1) and (2), and the user can obtain information about (3) based on the results. Another option, if relative abundance changes are of interest, is to use an RNA-seq count matrix analysis package such as DESeq2 (also an R package) to gather statistics on the log-fold changes from one sample group to another.","title":"Read-pair Haplotyping"},{"location":"documentation/usermanual/","text":"Workflow Parameters Parameters for each of the workflow components within the AmrPlusPlus pipeline can be customized by the user. Here, we provide detailed descriptions for each of the input parameters for SNPFinder and CoverageSampler. It may be desirable to set custom inputs for tools like Trimmomatic 4 and Burrows Wheeler Aligner 5 . If you wish to do so, please see the Trimmomatic User Manual , as well as the BWA User Manual before doing so. SNPFinder SNPFinder Filter on unique alignments SNPFinder only has one user defined parameter. In order to understand this parameter, we need to understand BWA's behavior. When BWA finds a read that aligns equally well to multiple resistance genes, it flags that read as having multiple alignments. By default, SNPFinder will include those reads when identifying haplotypes, however if you want to only consider reads with single alignments, check the box under Filter on unique alignments . Rarefaction Analyzer Rarefaction Analyzer Perform both rarefaction and calculation of gene fraction. Depending on what type of analysis you want to do, you can change the parameters to fit your needs. Below, we describe some common usage scenarios. Starting sample level If you want to perform rarefaction on your data, this would be the lowest rarefaction level. For example, if you want to rarefy your data down to 5% of the total you would input 5. However, if you only want to look at all of the alignments in your data (and not rarefaction), then set this parameter to 100. Ending sample level If you want to perform rarefaction on your data, this would be the highest rarefaction level. For example, if you want to rarefy your data from 5% to 95% of the total, you would input 5% for the \"starting sample level\" and 95% for the ending sample level. However, if you only want to look at all of the alignments in your data (and not perform rarefaction), then set this to 100. Gene fraction threshold This is the thresold for identifying \"positives\" within your sample. For instance, if you only want to identify genes that have at least 1 read aligning to at least 80% of their bases, then you would set this to 80. If you want to identify only those genes that are completely aligned across their entire length, set this to 100. If you want to identify all hits to all genes, then set this to 0. Amount of sample levels to skip If you are performing rarefaction, this sets the increments for the rarefaction. For example, if you want to rarefy from 5% to 95% of your data in increments of 5% points, then set this to 5. In this example, you would then get all of the genes identified for 5, 10, 15, 20, ..., 90, 95% of your data. If you only want to look at all of the alignments in your data and not perform rarefaction, then set this parameter to 1. Iterations per sample level If you are performing rarefaction, and you want to produce an average for each rarefaction level, you can specify here how many samplings you want to perform at each rarefaction level. For instance, if you set this to 10, and \"starting sample level\", \"ending sample level\" and \"amount of sample levels to skip\" are set to 5, 95 and 5, respectively, then the program will perform 10 unique subsamples of the data at the 5% level, 10 at the 10% level, 10 at the 15% level, etc.. You can then average the output from each subsample at each level in order to get a smooth rarefaction curve for your data.","title":"User Manual (Options and Settings)"},{"location":"documentation/usermanual/#workflow-parameters","text":"Parameters for each of the workflow components within the AmrPlusPlus pipeline can be customized by the user. Here, we provide detailed descriptions for each of the input parameters for SNPFinder and CoverageSampler. It may be desirable to set custom inputs for tools like Trimmomatic 4 and Burrows Wheeler Aligner 5 . If you wish to do so, please see the Trimmomatic User Manual , as well as the BWA User Manual before doing so.","title":"Workflow Parameters"},{"location":"documentation/usermanual/#snpfinder","text":"SNPFinder","title":"SNPFinder"},{"location":"documentation/usermanual/#filter-on-unique-alignments","text":"SNPFinder only has one user defined parameter. In order to understand this parameter, we need to understand BWA's behavior. When BWA finds a read that aligns equally well to multiple resistance genes, it flags that read as having multiple alignments. By default, SNPFinder will include those reads when identifying haplotypes, however if you want to only consider reads with single alignments, check the box under Filter on unique alignments .","title":"Filter on unique alignments"},{"location":"documentation/usermanual/#rarefaction-analyzer","text":"Rarefaction Analyzer","title":"Rarefaction Analyzer"},{"location":"documentation/usermanual/#perform-both-rarefaction-and-calculation-of-gene-fraction","text":"Depending on what type of analysis you want to do, you can change the parameters to fit your needs. Below, we describe some common usage scenarios.","title":"Perform both rarefaction and calculation of gene fraction."},{"location":"documentation/usermanual/#starting-sample-level","text":"If you want to perform rarefaction on your data, this would be the lowest rarefaction level. For example, if you want to rarefy your data down to 5% of the total you would input 5. However, if you only want to look at all of the alignments in your data (and not rarefaction), then set this parameter to 100.","title":"Starting sample level"},{"location":"documentation/usermanual/#ending-sample-level","text":"If you want to perform rarefaction on your data, this would be the highest rarefaction level. For example, if you want to rarefy your data from 5% to 95% of the total, you would input 5% for the \"starting sample level\" and 95% for the ending sample level. However, if you only want to look at all of the alignments in your data (and not perform rarefaction), then set this to 100.","title":"Ending sample level"},{"location":"documentation/usermanual/#gene-fraction-threshold","text":"This is the thresold for identifying \"positives\" within your sample. For instance, if you only want to identify genes that have at least 1 read aligning to at least 80% of their bases, then you would set this to 80. If you want to identify only those genes that are completely aligned across their entire length, set this to 100. If you want to identify all hits to all genes, then set this to 0.","title":"Gene fraction threshold"},{"location":"documentation/usermanual/#amount-of-sample-levels-to-skip","text":"If you are performing rarefaction, this sets the increments for the rarefaction. For example, if you want to rarefy from 5% to 95% of your data in increments of 5% points, then set this to 5. In this example, you would then get all of the genes identified for 5, 10, 15, 20, ..., 90, 95% of your data. If you only want to look at all of the alignments in your data and not perform rarefaction, then set this parameter to 1.","title":"Amount of sample levels to skip"},{"location":"documentation/usermanual/#iterations-per-sample-level","text":"If you are performing rarefaction, and you want to produce an average for each rarefaction level, you can specify here how many samplings you want to perform at each rarefaction level. For instance, if you set this to 10, and \"starting sample level\", \"ending sample level\" and \"amount of sample levels to skip\" are set to 5, 95 and 5, respectively, then the program will perform 10 unique subsamples of the data at the 5% level, 10 at the 10% level, 10 at the 15% level, etc.. You can then average the output from each subsample at each level in order to get a smooth rarefaction curve for your data.","title":"Iterations per sample level"},{"location":"running/runworkflow/","text":"Run AMR++ Workflow Now that we've got our data uploaded to our Galaxy server, it's time to run the workflow. Step 1: Navigate to the Workflow Tab Navigate to the Workflow Tab See the workflow tab circled in red below on the Galaxy homepage: Then click on the workflow you imported earlier and select Run You will be redirected to a page (see below) displaying each component of the workflow. Step 2: Select the Datasets Select the Datasets First, select the forward read pair. Then, select the second read pair. Next, select the host genome and resistance database. If you wish to customize any of the workflow components, please see the Workflow Parameters section before proceeding. Once the datasets have been selected, simply click the Run workflow button (circled in red). Step 3: View the Outputs View the Outputs When the workflow completes, you can find all intermediate and final outputs in the Galaxy history pane. The outputs you will be most interested in come from the SNPFinder and CoverageSampler modules. To view the outputs, simply click on the view data icon (circled in red). Once the datasets have been selected, simply click the Run workflow button (circled in red). These outputs can then be downloaded to your local machine by clicking on the download icon (circled in red). For more information on interpreting the output from each of these tools, please see the CoverageSampler and SNPFinder output descriptions.","title":"Run AMR++ Workflow"},{"location":"running/runworkflow/#run-amr-workflow","text":"Now that we've got our data uploaded to our Galaxy server, it's time to run the workflow. Step 1: Navigate to the Workflow Tab","title":"Run AMR++ Workflow"},{"location":"running/runworkflow/#navigate-to-the-workflow-tab","text":"See the workflow tab circled in red below on the Galaxy homepage: Then click on the workflow you imported earlier and select Run You will be redirected to a page (see below) displaying each component of the workflow. Step 2: Select the Datasets","title":"Navigate to the Workflow Tab"},{"location":"running/runworkflow/#select-the-datasets","text":"First, select the forward read pair. Then, select the second read pair. Next, select the host genome and resistance database. If you wish to customize any of the workflow components, please see the Workflow Parameters section before proceeding. Once the datasets have been selected, simply click the Run workflow button (circled in red). Step 3: View the Outputs","title":"Select the Datasets"},{"location":"running/runworkflow/#view-the-outputs","text":"When the workflow completes, you can find all intermediate and final outputs in the Galaxy history pane. The outputs you will be most interested in come from the SNPFinder and CoverageSampler modules. To view the outputs, simply click on the view data icon (circled in red). Once the datasets have been selected, simply click the Run workflow button (circled in red). These outputs can then be downloaded to your local machine by clicking on the download icon (circled in red). For more information on interpreting the output from each of these tools, please see the CoverageSampler and SNPFinder output descriptions.","title":"View the Outputs"},{"location":"running/upload/","text":"Upload Data into AMR++ Tutorial Data In the Use Tutorial Data section , we upload a sample data set using the Get Data module. This section is for those who are new to Galaxy and who want to get more comfortable with the Galaxy interface. Upload Your Data In the Upload My Own Data section, we use FileZilla to upload data via FTP. This section is for those who have large data sets (>2 GB) that they want to upload and run. Use Tutorial Data New to Galaxy? This section should get you up to speed with Galaxy and how to upload data. Step 1 Download Sample Data Let's get some sample data. Download the example data . The example data in this tutorial was taken from the full dataset of the human genome (hg38) , along with a paired metagenome sample (SRR532663) from the Human Microbiome Project (HMP) on NCBI. Once downloaded, unzip the sample_data.zip archive. You should see four files: SRR532663_1.fastq SRR532663_2.fastq production_resistance_database.fasta chr21.fasta Step 2 Upload Data There are a couple ways that we can upload these files to Galaxy: Via the Galaxy Get Data module Via a file transfer protocol (FTP) Note Currently, the Geta Data module only supports file uploads that are less than 2GB . If you wish to upload files larger than 2GB, you will need some FTP software such as FileZilla , however, it is not required for the sample data provided in this tutorial. Let's upload our data to Galaxy. First, make sure that your Galaxy server is running. Right now, you should be staring at a page similar to the following: Click on the Get Data link circled in red, and navigate to the underlined Upload File link. From here, we are given the options of Choosing a local file (highlighted in blue) or Choosing an FTP file (highlighted in orange). Let's choose a local file since our data is less than 2GB. If you want to upload via FTP, see the Upload My Own Data section. Navigate to the folder where you extracted the sample data, select the appropriate datasets, and upload them. Once selected, navigate to the Type column (circled in red) and specify the file type (highlighted in blue) for each dataset from the drop down menu. For each fastq dataset, select the fastqsanger option, and for each fasta dataset, select the fasta option. Next, click the Start button to begin uploading the data to your Galaxy server. If everything goes well, you should see all green. That's good! You can find the uploaded datasets in the right hand side of the Galaxy homepage. Now, let's head over to the Run Workflow section to run the pipeline. - OR - Upload Your Own Data Using FTP to Manage Your Data In this section, we'll cover what you need to know to upload your own data via FTP. If you haven't already done so, head on over to FileZilla and download their FTP client. It's free and very easy to use. Step 1 Enter FTP Credentials Connecting to your FTP server is really easy. Navigate to the site manager (circled in red): Click on the New Site button (circled in red) and enter a name for your FTP connection. Next, click on the Transfer Settings button (circled in orange) and check the Active radio button under Transfer mode . Go back to the General tab and enter in your credentials; replacing the hostname with your own. Under User , enter in admin@galaxy.org and under Password enter admin . Step 2 Transfer Files Once connected, we can upload some files. On my machine, I have files on my Desktop under a directory called sample data (highlighted in blue). Navigate to the folder where your data is. You will see a list of files in that directory through the FTP client interface (highlighted in red). Simply drag and drop the desired files to the root directory as illustrated below. Step 3 Upload FTP Files Once the transfer has completed, navigate to the Get Data module on your Galaxy homepage and select the Upload File link. Next, click on the Choose FTP file option. Check all the boxes for each dataset. Next, find the Type tab in the next window and specify the file type for each file from the drop down menu. Choose fastq sanger for your fastq datasets and fasta for your fasta datasets. That's it! You should then see the files loading in your History pane on the Galaxy homepage. Now, let's head over to the Run Workflow section to run the pipeline. Note You may need to refresh the history pane to see the uploaded datasets, which you can do by clicking on the Refresh history icon directly to the right of the history pane.","title":"Upload Data into AMR++"},{"location":"running/upload/#upload-data-into-amr","text":"","title":"Upload Data into AMR++"},{"location":"running/upload/#tutorial-data","text":"In the Use Tutorial Data section , we upload a sample data set using the Get Data module. This section is for those who are new to Galaxy and who want to get more comfortable with the Galaxy interface.","title":"Tutorial Data"},{"location":"running/upload/#upload-your-data","text":"In the Upload My Own Data section, we use FileZilla to upload data via FTP. This section is for those who have large data sets (>2 GB) that they want to upload and run. Use Tutorial Data","title":"Upload Your Data"},{"location":"running/upload/#new-to-galaxy","text":"This section should get you up to speed with Galaxy and how to upload data.","title":"New to Galaxy?"},{"location":"running/upload/#step-1","text":"","title":"Step 1"},{"location":"running/upload/#download-sample-data","text":"Let's get some sample data. Download the example data . The example data in this tutorial was taken from the full dataset of the human genome (hg38) , along with a paired metagenome sample (SRR532663) from the Human Microbiome Project (HMP) on NCBI. Once downloaded, unzip the sample_data.zip archive. You should see four files: SRR532663_1.fastq SRR532663_2.fastq production_resistance_database.fasta chr21.fasta","title":"Download Sample Data"},{"location":"running/upload/#step-2","text":"","title":"Step 2"},{"location":"running/upload/#upload-data","text":"There are a couple ways that we can upload these files to Galaxy: Via the Galaxy Get Data module Via a file transfer protocol (FTP) Note Currently, the Geta Data module only supports file uploads that are less than 2GB . If you wish to upload files larger than 2GB, you will need some FTP software such as FileZilla , however, it is not required for the sample data provided in this tutorial. Let's upload our data to Galaxy. First, make sure that your Galaxy server is running. Right now, you should be staring at a page similar to the following: Click on the Get Data link circled in red, and navigate to the underlined Upload File link. From here, we are given the options of Choosing a local file (highlighted in blue) or Choosing an FTP file (highlighted in orange). Let's choose a local file since our data is less than 2GB. If you want to upload via FTP, see the Upload My Own Data section. Navigate to the folder where you extracted the sample data, select the appropriate datasets, and upload them. Once selected, navigate to the Type column (circled in red) and specify the file type (highlighted in blue) for each dataset from the drop down menu. For each fastq dataset, select the fastqsanger option, and for each fasta dataset, select the fasta option. Next, click the Start button to begin uploading the data to your Galaxy server. If everything goes well, you should see all green. That's good! You can find the uploaded datasets in the right hand side of the Galaxy homepage. Now, let's head over to the Run Workflow section to run the pipeline. - OR - Upload Your Own Data","title":"Upload Data"},{"location":"running/upload/#using-ftp-to-manage-your-data","text":"In this section, we'll cover what you need to know to upload your own data via FTP. If you haven't already done so, head on over to FileZilla and download their FTP client. It's free and very easy to use.","title":"Using FTP to Manage Your Data"},{"location":"running/upload/#step-1_1","text":"","title":"Step 1"},{"location":"running/upload/#enter-ftp-credentials","text":"Connecting to your FTP server is really easy. Navigate to the site manager (circled in red): Click on the New Site button (circled in red) and enter a name for your FTP connection. Next, click on the Transfer Settings button (circled in orange) and check the Active radio button under Transfer mode . Go back to the General tab and enter in your credentials; replacing the hostname with your own. Under User , enter in admin@galaxy.org and under Password enter admin .","title":"Enter FTP Credentials"},{"location":"running/upload/#step-2_1","text":"","title":"Step 2"},{"location":"running/upload/#transfer-files","text":"Once connected, we can upload some files. On my machine, I have files on my Desktop under a directory called sample data (highlighted in blue). Navigate to the folder where your data is. You will see a list of files in that directory through the FTP client interface (highlighted in red). Simply drag and drop the desired files to the root directory as illustrated below.","title":"Transfer Files"},{"location":"running/upload/#step-3","text":"","title":"Step 3"},{"location":"running/upload/#upload-ftp-files","text":"Once the transfer has completed, navigate to the Get Data module on your Galaxy homepage and select the Upload File link. Next, click on the Choose FTP file option. Check all the boxes for each dataset. Next, find the Type tab in the next window and specify the file type for each file from the drop down menu. Choose fastq sanger for your fastq datasets and fasta for your fasta datasets. That's it! You should then see the files loading in your History pane on the Galaxy homepage. Now, let's head over to the Run Workflow section to run the pipeline. Note You may need to refresh the history pane to see the uploaded datasets, which you can do by clicking on the Refresh history icon directly to the right of the history pane.","title":"Upload FTP Files"},{"location":"setup/import/","text":"Import Workflow Before we can run some data, we need to import the AmrPlusPlus workflow. Follow the instructions below. Workflow Installation Step 1 Step 1 Navigate to the Workflow tab at the top of the Galaxy homepage. Step 2 Step 2 Click on the Upload or import workflow tab at the top right of the page. Step 3 Step 3 Click on the Visit myExperiment link at the bottom of the page. Step 4 Step 4 Type in amrplusplus into the search box. Step 5 Step 5 You will see two workflows (amrplusplus single-end workflow and amrplusplus paired-end workflow). Click on the amrplusplus paired-end workflow link. You can download the single-end workflow, but we'll be using the paired workflow when we get to the Run Workflow section. Then, click on the Import button in the middle of the page. Step 6 Step 6 Now, let's upload some data .","title":"Import AMR++ Workflow"},{"location":"setup/import/#import-workflow","text":"Before we can run some data, we need to import the AmrPlusPlus workflow. Follow the instructions below.","title":"Import Workflow"},{"location":"setup/import/#workflow-installation","text":"Step 1","title":"Workflow Installation"},{"location":"setup/import/#step-1","text":"Navigate to the Workflow tab at the top of the Galaxy homepage. Step 2","title":"Step 1"},{"location":"setup/import/#step-2","text":"Click on the Upload or import workflow tab at the top right of the page. Step 3","title":"Step 2"},{"location":"setup/import/#step-3","text":"Click on the Visit myExperiment link at the bottom of the page. Step 4","title":"Step 3"},{"location":"setup/import/#step-4","text":"Type in amrplusplus into the search box. Step 5","title":"Step 4"},{"location":"setup/import/#step-5","text":"You will see two workflows (amrplusplus single-end workflow and amrplusplus paired-end workflow). Click on the amrplusplus paired-end workflow link. You can download the single-end workflow, but we'll be using the paired workflow when we get to the Run Workflow section. Then, click on the Import button in the middle of the page. Step 6","title":"Step 5"},{"location":"setup/import/#step-6","text":"Now, let's upload some data .","title":"Step 6"},{"location":"setup/installation/","text":"Installation The following installation will take approximately 30 minutes. Software Requirements To install Docker, you will need access to one of the following operating systems: Mac OS X (10.8 or above) Linux 64-bit Docker Install via Docker Why Install via Docker? Docker packages an entire piece of software into its own filesystem. Docker rids users of dependency nightmares caused by complex software. Step 1 Download Docker Mac Users: Follow the instructions here . Linux Users: Follow the instructions here . Note You must have sudo privileges to install Docker via Linux. Step 2 Start Docker with a Mac Open your Launchpad, and click on the DockerQuickStart icon. This will open a terminal and start Docker using a default virtual machine. Be sure to take note of the IP address (highlighted in red) Docker was started on. The IP address will be different than the one highlighted below. To launch your Galaxy instance, type this exact command into the terminal (omitting the '$' sign): $ docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus Start Docker with Linux Open a terminal, and type these exact commands (omitting the '$' sign): $ sudo service docker start $ sudo docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus Note When running these commands for the first time, Docker will go out and look for the chrisd/amrplusplus repository and download the latest AmrPlusPlus Docker image. When the install completes, you should see a message similar to the one below. $ Digest: sha256:7e992b68ddb9a2e37a9f2b862de015445912d20cc98d13970603939330b0433e $ Status: Downloaded newer image for chrisd/amrplusplus:latest $ 10ab4d35cf798a2e46a0ec4e2eaf15377c3558772b3f5d0e1107025a9b922f76 If you see this message, that means the latest version of the pipeline was downloaded successfully and is currently running on your machine. Step 3 Connecting to the Server on a Mac Open a web browser, and navigate to: http://default-ip:8080 Warning Replace deafult-ip with the IP address Docker was started on. For example, if the IP address was 192.000.00.000, then you would enter http://192.000.00.000:8080 into your web browser. If you forgot the IP address, you can find it by scrolling to the top of your terminal. Connecting to the Server on Linux Open a web browser, and navigate to: localhost:8080 Once connected, you should see a page similar to the following: Step 4 Log in to Server Next, we need to login. From the navigation bar at the top of the Galaxy homepage, click on the User tab and goto Login . In the Username field, enter admin@galaxy.org and in the Password field, enter admin and click on the Login button. Step 5 Import Workflow Next, we need to Import the Workflow . Galaxy Install via Galaxy Before You Begin If you installed Galaxy via Docker, you do not need to read this section. Galaxy comes installed when you run Docker. See the Import Workflow for next steps. This section is only for those who have a production Galaxy server and wish to download the AmrPlusPlus pipeline via the Galaxy Main Toolshed. Software Requirements Production Galaxy Server Admin account GNU Make and GCC compiler Tool Installation Log in to your Galaxy server with your admin account. Find the admin tab in the navigation bar -> Search Tool Shed -> Galaxy Main Toolshed ->Browse Valid Repositories -> Metagenomics -> suite_amrplusplus -> Preview and Install. Click on the Install button at the top of the page. Make sure the Handle Repository Dependencies and Handle Tool Dependencies boxes are checked. In the Add New Tool Section Panel, enter AmrPlusPlus into the text box. Click on the Install button at the bottom of the page.","title":"Installation to Run AMR++"},{"location":"setup/installation/#installation","text":"The following installation will take approximately 30 minutes.","title":"Installation"},{"location":"setup/installation/#software-requirements","text":"To install Docker, you will need access to one of the following operating systems: Mac OS X (10.8 or above) Linux 64-bit","title":"Software Requirements"},{"location":"setup/installation/#docker","text":"Install via Docker Why Install via Docker? Docker packages an entire piece of software into its own filesystem. Docker rids users of dependency nightmares caused by complex software.","title":"Docker"},{"location":"setup/installation/#step-1","text":"","title":"Step 1"},{"location":"setup/installation/#download-docker","text":"Mac Users: Follow the instructions here . Linux Users: Follow the instructions here . Note You must have sudo privileges to install Docker via Linux.","title":"Download Docker"},{"location":"setup/installation/#step-2","text":"","title":"Step 2"},{"location":"setup/installation/#start-docker-with-a-mac","text":"Open your Launchpad, and click on the DockerQuickStart icon. This will open a terminal and start Docker using a default virtual machine. Be sure to take note of the IP address (highlighted in red) Docker was started on. The IP address will be different than the one highlighted below. To launch your Galaxy instance, type this exact command into the terminal (omitting the '$' sign): $ docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus","title":"Start Docker with a Mac"},{"location":"setup/installation/#start-docker-with-linux","text":"Open a terminal, and type these exact commands (omitting the '$' sign): $ sudo service docker start $ sudo docker run -d -p 8080:80 -p 8021:21 chrisd/amrplusplus Note When running these commands for the first time, Docker will go out and look for the chrisd/amrplusplus repository and download the latest AmrPlusPlus Docker image. When the install completes, you should see a message similar to the one below. $ Digest: sha256:7e992b68ddb9a2e37a9f2b862de015445912d20cc98d13970603939330b0433e $ Status: Downloaded newer image for chrisd/amrplusplus:latest $ 10ab4d35cf798a2e46a0ec4e2eaf15377c3558772b3f5d0e1107025a9b922f76 If you see this message, that means the latest version of the pipeline was downloaded successfully and is currently running on your machine.","title":"Start Docker with Linux"},{"location":"setup/installation/#step-3","text":"","title":"Step 3"},{"location":"setup/installation/#connecting-to-the-server-on-a-mac","text":"Open a web browser, and navigate to: http://default-ip:8080 Warning Replace deafult-ip with the IP address Docker was started on. For example, if the IP address was 192.000.00.000, then you would enter http://192.000.00.000:8080 into your web browser. If you forgot the IP address, you can find it by scrolling to the top of your terminal.","title":"Connecting to the Server on a Mac"},{"location":"setup/installation/#connecting-to-the-server-on-linux","text":"Open a web browser, and navigate to: localhost:8080 Once connected, you should see a page similar to the following:","title":"Connecting to the Server on Linux"},{"location":"setup/installation/#step-4","text":"","title":"Step 4"},{"location":"setup/installation/#log-in-to-server","text":"Next, we need to login. From the navigation bar at the top of the Galaxy homepage, click on the User tab and goto Login . In the Username field, enter admin@galaxy.org and in the Password field, enter admin and click on the Login button.","title":"Log in to Server"},{"location":"setup/installation/#step-5","text":"","title":"Step 5"},{"location":"setup/installation/#import-workflow","text":"Next, we need to Import the Workflow .","title":"Import Workflow"},{"location":"setup/installation/#galaxy","text":"Install via Galaxy","title":"Galaxy"},{"location":"setup/installation/#before-you-begin","text":"If you installed Galaxy via Docker, you do not need to read this section. Galaxy comes installed when you run Docker. See the Import Workflow for next steps. This section is only for those who have a production Galaxy server and wish to download the AmrPlusPlus pipeline via the Galaxy Main Toolshed.","title":"Before You Begin"},{"location":"setup/installation/#software-requirements_1","text":"Production Galaxy Server Admin account GNU Make and GCC compiler","title":"Software Requirements"},{"location":"setup/installation/#tool-installation","text":"Log in to your Galaxy server with your admin account. Find the admin tab in the navigation bar -> Search Tool Shed -> Galaxy Main Toolshed ->Browse Valid Repositories -> Metagenomics -> suite_amrplusplus -> Preview and Install. Click on the Install button at the top of the page. Make sure the Handle Repository Dependencies and Handle Tool Dependencies boxes are checked. In the Add New Tool Section Panel, enter AmrPlusPlus into the text box. Click on the Install button at the bottom of the page.","title":"Tool Installation"}]}